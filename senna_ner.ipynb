{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import constants as const\n",
    "from senna_ner import SennaNER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_design_list = [{'layer_type': 'full_cn', 'output_shape': [300], 'activation': 'relu'},\n",
    "                  {'layer_type': 'full_cn', 'output_shape': [len(const.LIST_KEYWORD_TAGS)]}]\n",
    "\n",
    "model_details_dict = {'project_name': 'reuters',\n",
    "                      'loss_type': 'sentence_level',\n",
    "                      'nn_design_list': nn_design_list,\n",
    "                      'wdvec_name': 'wdvec_2018-07-26T13-02-36.910667',\n",
    "                      'model_name': 'reuters_model'} # 'reuters_model_2019-03-21T15-44-56.214733'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/smflores/.tfenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/smflores/.tfenv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "            <script>\n",
       "              function load() {\n",
       "                document.getElementById(&quot;graph0.9355421351557515&quot;).pbtxt = 'node {\\n  name: &quot;inputs&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 270\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;target&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;breaks&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/inputs_shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;inputs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/Cast/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 270\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/Cast/x&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/truediv/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/truediv/x&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\016\\\\001\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/mul&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/variable_init/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 270\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/weight_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/weight_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/biases_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n  input: &quot;neural_network/layer_1_full_cn/variable_init/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/biases_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/weight_mul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;inputs&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/biases_add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_mul_1&quot;\\n  input: &quot;neural_network/layer_1_full_cn/biases_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_full_cn/activation_1&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;neural_network/layer_1_full_cn/biases_add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_1_output_shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;neural_network/layer_1_full_cn/activation_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/Cast/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 300\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/Cast/x&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/truediv/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/truediv/x&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/mul&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/variable_init/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/weight_2/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/weight_2/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/biases_2/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n  input: &quot;neural_network/layer_2_full_cn/variable_init/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/biases_2/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/weight_mul_2&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;neural_network/layer_1_full_cn/activation_1&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/biases_add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_mul_2&quot;\\n  input: &quot;neural_network/layer_2_full_cn/biases_2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_full_cn/activation_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;neural_network/layer_2_full_cn/biases_add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;neural_network/layer_2_output_shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;neural_network/layer_2_full_cn/activation_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;neural_network/layer_2_full_cn/activation_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal/TruncatedNormal&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal/mul&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/TruncatedNormal&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/mul&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_1/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/TruncatedNormal&quot;\\n  op: &quot;TruncatedNormal&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/TruncatedNormal&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/variable_init/truncated_normal_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/mul&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_2/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/start_weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/start_weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;loss_function/transition_weights/start_weights&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/start_weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/transition_weights/start_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/trans_weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/trans_weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;loss_function/transition_weights/trans_weights&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/trans_weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/transition_weights/trans_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/final_weights&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/final_weights/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;loss_function/transition_weights/final_weights&quot;\\n  input: &quot;loss_function/transition_weights/variable_init/truncated_normal_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/transition_weights/final_weights/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/transition_weights/final_weights&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;breaks&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/Shape&quot;\\n  input: &quot;loss_function/strided_slice/stack&quot;\\n  input: &quot;loss_function/strided_slice/stack_1&quot;\\n  input: &quot;loss_function/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/strided_slice&quot;\\n  input: &quot;loss_function/sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;loss_function/zeros/shape_as_tensor&quot;\\n  input: &quot;loss_function/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss_function/while/Enter&quot;\\n  input: &quot;loss_function/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss_function/while/Enter_1&quot;\\n  input: &quot;loss_function/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;loss_function/while/Merge&quot;\\n  input: &quot;loss_function/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;loss_function/while/Less&quot;\\n}\\nnode {\\n  name: &quot;loss_function/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss_function/while/Merge&quot;\\n  input: &quot;loss_function/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss_function/while/Merge_1&quot;\\n  input: &quot;loss_function/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/Identity&quot;\\n  input: &quot;loss_function/while/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/add&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/strided_slice/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice/stack&quot;\\n  input: &quot;loss_function/while/strided_slice/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;breaks&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/Identity&quot;\\n  input: &quot;loss_function/while/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_2/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/add_1&quot;\\n  input: &quot;loss_function/while/add_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_1/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/add_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_1/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/add_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/strided_slice/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_1/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_1/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_3/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/Identity&quot;\\n  input: &quot;loss_function/while/add_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_2/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_2/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/add_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/strided_slice/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_2/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_2/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/while/strided_slice_1&quot;\\n  input: &quot;loss_function/while/strided_slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice/begin/1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/strided_slice&quot;\\n  input: &quot;loss_function/while/Slice/begin/1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice/size/1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/sub&quot;\\n  input: &quot;loss_function/while/Slice/size/1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;loss_function/while/Slice/Enter&quot;\\n  input: &quot;loss_function/while/Slice/begin&quot;\\n  input: &quot;loss_function/while/Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;neural_network/layer_2_full_cn/activation_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice_1/begin/1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/strided_slice&quot;\\n  input: &quot;loss_function/while/Slice_1/begin/1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice_1/size/1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice_1/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/sub&quot;\\n  input: &quot;loss_function/while/Slice_1/size/1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;loss_function/while/Slice_1/Enter&quot;\\n  input: &quot;loss_function/while/Slice_1/begin&quot;\\n  input: &quot;loss_function/while/Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Slice_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;target&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;loss_function/while/Slice_1&quot;\\n  input: &quot;loss_function/while/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_3/stack&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_3/stack_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_3/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_3&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/Shape&quot;\\n  input: &quot;loss_function/while/strided_slice_3/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_3/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_3/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_4/stack&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_4/stack_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_4/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_4&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  input: &quot;loss_function/while/strided_slice_4/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_4/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_4/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_4&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/add_4/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_4/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/transition_weights/start_weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/while/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/add_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss_function/while/while/Enter&quot;\\n  input: &quot;loss_function/while/while/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss_function/while/while/Enter_1&quot;\\n  input: &quot;loss_function/while/while/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;loss_function/while/while/Merge&quot;\\n  input: &quot;loss_function/while/while/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;loss_function/while/while/Less&quot;\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss_function/while/while/Merge&quot;\\n  input: &quot;loss_function/while/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss_function/while/while/Merge_1&quot;\\n  input: &quot;loss_function/while/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/while/while/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/while/while/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;loss_function/while/while/Identity_1&quot;\\n  input: &quot;loss_function/while/while/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/Reshape&quot;\\n  input: &quot;loss_function/while/while/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 17\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while/add/Enter_1&quot;\\n  input: &quot;loss_function/while/while/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/transition_weights/trans_weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/while/add/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Max/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;loss_function/while/while/add&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Max/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/IsFinite&quot;\\n  op: &quot;IsFinite&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/IsFinite&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Max&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/StopGradient&quot;\\n  op: &quot;StopGradient&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/while/while/add&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Exp&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/StopGradient&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/ReduceLogSumExp/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Log&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while/Identity&quot;\\n  input: &quot;loss_function/while/while/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/strided_slice/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/strided_slice/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while/add_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/while/strided_slice/Enter&quot;\\n  input: &quot;loss_function/while/while/strided_slice/stack&quot;\\n  input: &quot;loss_function/while/while/strided_slice/stack_1&quot;\\n  input: &quot;loss_function/while/while/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/strided_slice/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Add&quot;\\n  input: &quot;loss_function/while/while/strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add_3/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/add_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while/Identity&quot;\\n  input: &quot;loss_function/while/while/add_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;loss_function/while/while/add_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;loss_function/while/while/add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;loss_function/while/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;loss_function/while/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_5/stack&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_5/stack_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_5/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_5&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/ArgMax&quot;\\n  input: &quot;loss_function/while/strided_slice_5/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_5/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_5/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_5/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_5&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/strided_slice_5&quot;\\n  input: &quot;loss_function/while/add_5/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_6/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/strided_slice_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_6/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/add_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_6/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_6/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;loss_function/while/strided_slice_6/stack_2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_6&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/add_4/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_6/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_6/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_6/Cast&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_7/stack&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_7/stack_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_7/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_7&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/ArgMax&quot;\\n  input: &quot;loss_function/while/strided_slice_7/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_7/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_7/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_6/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_6&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/strided_slice_7&quot;\\n  input: &quot;loss_function/while/add_6/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_8/stack/0&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_8/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/strided_slice_8/stack/0&quot;\\n  input: &quot;loss_function/while/strided_slice_7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_8/stack_1/0&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_8/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/strided_slice_8/stack_1/0&quot;\\n  input: &quot;loss_function/while/add_6&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_8/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_8/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;loss_function/while/strided_slice_8/stack_2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_8&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  input: &quot;loss_function/while/strided_slice_8/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_8/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_8/Cast&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_7&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/strided_slice_6&quot;\\n  input: &quot;loss_function/while/strided_slice_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/while_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/add_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss_function/while/while_1/Enter&quot;\\n  input: &quot;loss_function/while/while_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;loss_function/while/while_1/Enter_1&quot;\\n  input: &quot;loss_function/while/while_1/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Less&quot;\\n  op: &quot;Less&quot;\\n  input: &quot;loss_function/while/while_1/Merge&quot;\\n  input: &quot;loss_function/while/while_1/Less/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Less/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/LoopCond&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;loss_function/while/while_1/Less&quot;\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss_function/while/while_1/Merge&quot;\\n  input: &quot;loss_function/while/while_1/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/Merge&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;loss_function/while/while_1/Merge_1&quot;\\n  input: &quot;loss_function/while/while_1/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/Merge_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/while/while_1/Switch:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Identity_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/while/while_1/Switch_1:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/sub/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  input: &quot;loss_function/while/while_1/sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/sub&quot;\\n  input: &quot;loss_function/while/while_1/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/add&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice/Enter&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice/stack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice/stack_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/ArgMax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  input: &quot;loss_function/while/while_1/add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_1/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_1/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/add_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice/Enter&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_1/stack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_1/stack_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_2/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice&quot;\\n  input: &quot;loss_function/while/while_1/add_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_3/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_3&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_1&quot;\\n  input: &quot;loss_function/while/while_1/add_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_2/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_2/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/add_2&quot;\\n  input: &quot;loss_function/while/while_1/add_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_2/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_2/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/stack_2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_2&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/Enter&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/stack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/stack_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/Cast&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/while/add/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_4&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/Identity_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_5/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_5&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  input: &quot;loss_function/while/while_1/add_5/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_3/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_3/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/add_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_3/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_3&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3/Enter&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3/stack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3/stack_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_6/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_6&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  input: &quot;loss_function/while/while_1/add_6/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_4/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_4/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/add_6&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_4/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_4&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice/Enter&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_4/stack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_4/stack_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_4/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_7/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_7&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_4&quot;\\n  input: &quot;loss_function/while/while_1/add_7/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_5/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_5/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/while_1/add_7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_5/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_5/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5/stack_2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/strided_slice_5&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5/stack&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5/stack_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5/Cast&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_8&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/add_4&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_9/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/add_9&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/Identity&quot;\\n  input: &quot;loss_function/while/while_1/add_9/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;loss_function/while/while_1/add_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;loss_function/while/while_1/add_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;loss_function/while/while_1/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/while_1/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;loss_function/while/while_1/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/while/while_1/Exit&quot;\\n  input: &quot;loss_function/while/sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_8/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_8&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/sub_1&quot;\\n  input: &quot;loss_function/while/add_8/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_9/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_9/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/add_8&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_9/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_9&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/ArgMax&quot;\\n  input: &quot;loss_function/while/strided_slice_9/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_9/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_9/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_9/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_9&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/strided_slice_9&quot;\\n  input: &quot;loss_function/while/add_9/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_10/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/strided_slice_9&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_10/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss_function/while/add_9&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_10/stack_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_10/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;loss_function/while/strided_slice_10/stack_2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_10&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/while/strided_slice_10/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_10/stack&quot;\\n  input: &quot;loss_function/while/strided_slice_10/stack_1&quot;\\n  input: &quot;loss_function/while/strided_slice_10/Cast&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/strided_slice_10/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;loss_function/transition_weights/final_weights/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_10&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while_1/Exit_1&quot;\\n  input: &quot;loss_function/while/strided_slice_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_11&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/while/Exit_1&quot;\\n  input: &quot;loss_function/while/strided_slice_10/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Max&quot;\\n  op: &quot;Max&quot;\\n  input: &quot;loss_function/while/add_11&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/IsFinite&quot;\\n  op: &quot;IsFinite&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Max&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/zeros_like&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Select&quot;\\n  op: &quot;Select&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/IsFinite&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Max&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/zeros_like&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/StopGradient&quot;\\n  op: &quot;StopGradient&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Select&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/while/add_11&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/StopGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Exp&quot;\\n  op: &quot;Exp&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Exp&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/StopGradient&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/ReduceLogSumExp/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Log&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/while/add_10&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_12/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/add_12&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss_function/while/Identity&quot;\\n  input: &quot;loss_function/while/add_12/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/sub_3&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss_function/while/Identity_1&quot;\\n  input: &quot;loss_function/while/sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;loss_function/while/add_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;loss_function/while/sub_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;loss_function/while/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/while/Exit_1&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;loss_function/while/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;loss_function/sub&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;loss_function/while/Exit_1&quot;\\n  input: &quot;loss_function/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice_1/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice_1/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice_1/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss_function/strided_slice_1&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;loss_function/truediv&quot;\\n  input: &quot;loss_function/strided_slice_1/stack&quot;\\n  input: &quot;loss_function/strided_slice_1/stack_1&quot;\\n  input: &quot;loss_function/strided_slice_1/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss_function/strided_slice_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/gradients/Shape&quot;\\n  input: &quot;optimizer/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Merge&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/f_count_1&quot;\\n  input: &quot;optimizer/gradients/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/Merge&quot;\\n  input: &quot;loss_function/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Add/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/Switch:1&quot;\\n  input: &quot;optimizer/gradients/Add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/Add&quot;\\n  input: &quot;^optimizer/gradients/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Slice_grad/sub/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Slice_grad/sub/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2_3&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/StackPushV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Merge_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/b_count_1&quot;\\n  input: &quot;optimizer/gradients/NextIteration_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/GreaterEqual&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;optimizer/gradients/Merge_1&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/GreaterEqual/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/b_count&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_2&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Switch_1&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/Merge_1&quot;\\n  input: &quot;optimizer/gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;optimizer/gradients/Switch_1:1&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/NextIteration_1&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/Sub&quot;\\n  input: &quot;^optimizer/gradients/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/Switch_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_count_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Merge_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/f_count_4&quot;\\n  input: &quot;optimizer/gradients/NextIteration_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Switch_2&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/Merge_2&quot;\\n  input: &quot;loss_function/while/while_1/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Add_1/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/Switch_2:1&quot;\\n  input: &quot;optimizer/gradients/Add_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/NextIteration_2&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/Add_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_5&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/Switch_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/f_count_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/f_count_5&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/Enter&quot;\\n  input: &quot;optimizer/gradients/f_count_5&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^optimizer/gradients/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/b_count_11&quot;\\n  input: &quot;^optimizer/gradients/b_count_7&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_3&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/StackPopV2&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_4&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/StackPopV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Merge_3&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/b_count_5&quot;\\n  input: &quot;optimizer/gradients/NextIteration_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/GreaterEqual_1&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;optimizer/gradients/Merge_3&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/GreaterEqual_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/b_count_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_6&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Switch_3&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/Merge_3&quot;\\n  input: &quot;optimizer/gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;optimizer/gradients/Switch_3:1&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/NextIteration_3&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/Sub_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_7&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/Switch_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_6&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_7&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Merge_4&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/f_count_7&quot;\\n  input: &quot;optimizer/gradients/NextIteration_4&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Switch_4&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/Merge_4&quot;\\n  input: &quot;loss_function/while/while/LoopCond&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Add_2/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Add_2&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/Switch_4:1&quot;\\n  input: &quot;optimizer/gradients/Add_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/NextIteration_4&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/Add_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPushV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_count_8&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/Switch_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/f_count_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/f_count_8&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/Enter_1&quot;\\n  input: &quot;optimizer/gradients/f_count_8&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/StackPopV2_1/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_8&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_9&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/StackPopV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Merge_5&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/b_count_9&quot;\\n  input: &quot;optimizer/gradients/NextIteration_5&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/GreaterEqual_2&quot;\\n  op: &quot;GreaterEqual&quot;\\n  input: &quot;optimizer/gradients/Merge_5&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/GreaterEqual_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/b_count_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_10&quot;\\n  op: &quot;LoopCond&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual_2&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Switch_5&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/Merge_5&quot;\\n  input: &quot;optimizer/gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;optimizer/gradients/Switch_5:1&quot;\\n  input: &quot;optimizer/gradients/GreaterEqual_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/NextIteration_5&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/Sub_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/b_sync&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/b_count_11&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/Switch_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/strided_slice_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/strided_slice_1_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/strided_slice_1_grad/Shape&quot;\\n  input: &quot;loss_function/strided_slice_1/stack&quot;\\n  input: &quot;loss_function/strided_slice_1/stack_1&quot;\\n  input: &quot;loss_function/strided_slice_1/stack_2&quot;\\n  input: &quot;optimizer/gradients/Fill&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/RealDiv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;optimizer/gradients/loss_function/strided_slice_1_grad/StridedSliceGrad&quot;\\n  input: &quot;loss_function/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/RealDiv&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;loss_function/while/Exit_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/RealDiv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Neg&quot;\\n  input: &quot;loss_function/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/RealDiv_2&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/RealDiv_1&quot;\\n  input: &quot;loss_function/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/strided_slice_1_grad/StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/RealDiv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Sum_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/truediv_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/truediv_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/truediv_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/truediv_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/truediv_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/Reshape_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/truediv_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/truediv_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/truediv_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;optimizer/gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Neg&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_3_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_3_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_3_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_3_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/Reshape_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_3_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_3_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_2_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_2_grad/Neg&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_3_grad/tuple/control_dependency_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_3_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_2_grad/Neg&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_2_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_3_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_10_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_10_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_10_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_3_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_10_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_10_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_3_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_2_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/sub_2_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/sub_2_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_10_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int64_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_10_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_10/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_10/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_10/stack&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_10/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_10/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Enter_1&quot;\\n  input: &quot;loss_function/while/strided_slice_10/stack_1&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_10/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc_2&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Const_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_10/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/Enter_2&quot;\\n  input: &quot;loss_function/while/strided_slice_10/Cast&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/ReduceLogSumExp/Sum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/ReduceLogSumExp/Sum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/Enter&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Sum&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/control_dependency&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Exit_1_grad/b_exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Log_grad/mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n  input: &quot;optimizer/gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/Switch&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sum_grad/Tile&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/ReduceLogSumExp/Exp&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/ReduceLogSumExp/Exp&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/Enter&quot;\\n  input: &quot;loss_function/while/ReduceLogSumExp/Exp&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Exp_grad/mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Neg&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_7_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/Enter_1_grad/Exit&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_7_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Enter_1_grad/Exit&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_7_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Enter_1_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_7_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Enter_1_grad/Exit&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_7_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Enter_1_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/control_dependency_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Reshape_grad/Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/ReduceLogSumExp/Reshape_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int64_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_7_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_6/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_6/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Enter&quot;\\n  input: &quot;loss_function/while/strided_slice_6/stack&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_6/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_6/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Enter_1&quot;\\n  input: &quot;loss_function/while/strided_slice_6/stack_1&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_6/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc_2&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Const_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_6/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/Enter_2&quot;\\n  input: &quot;loss_function/while/strided_slice_6/Cast&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_7_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/strided_slice_8_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/strided_slice_8_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/Shape&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_8/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_8/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter_1&quot;\\n  input: &quot;loss_function/while/strided_slice_8/stack&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_8/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_2&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_8/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter_2&quot;\\n  input: &quot;loss_function/while/strided_slice_8/stack_1&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_8/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_3&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Const_3&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/strided_slice_8/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPushV2_3&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/Enter_3&quot;\\n  input: &quot;loss_function/while/strided_slice_8/Cast&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_3&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_3/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/StackPopV2_3/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad/f_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/add_4_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/control_dependency&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/add_4_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/add_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/add_4_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/add_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int64_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/add_8_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_5/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_5/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5/stack&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_2&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_5/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_5/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_3&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5/stack_1&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_5/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc_2&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Const_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_5/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/Enter_5&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_5/Cast&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/add_4_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_2/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_2/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_1&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/stack&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_2/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_2/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_3&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/stack_1&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_2/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc_2&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Const_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_2/Cast&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/Enter_5&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_2/Cast&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3/Enter&quot;\\n  input: &quot;^loss_function/while/while_1/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_5_grad/StridedSliceGrad&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/Shape&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_3/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_3/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_3&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3/stack&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_3/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc_2&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while_1/strided_slice_3/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Enter_5&quot;\\n  input: &quot;loss_function/while/while_1/strided_slice_3/stack_1&quot;\\n  input: &quot;^optimizer/gradients/Add_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad/Const_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_1&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/add_4_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2_grad/StridedSliceGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Shape&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_1/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/b_acc&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/b_count_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3_grad/StridedSliceGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_11_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_11_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_11_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_11_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_11_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Exit_1_grad/b_exit&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_11_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_11_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/strided_slice_10_grad/StridedSliceGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Exit_1_grad/b_exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Switch_1_grad_1/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n  input: &quot;optimizer/gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/Merge_1_grad/Switch&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/Switch&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/Switch:1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Enter_1_grad/Exit&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/Enter_1_grad/Exit&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Enter_1_grad/Exit&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Enter_1_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Enter_1_grad/Exit&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/add_4_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Enter_1_grad/Exit&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Merge_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/strided_slice_6_grad/StridedSliceGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/strided_slice_4_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/strided_slice_4_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/Shape&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad/Const_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/add_2_grad/tuple/control_dependency&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add_2_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add_2_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/Switch_1_grad/b_switch&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/while/strided_slice/Enter&quot;\\n  input: &quot;^loss_function/while/while/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad&quot;\\n  op: &quot;StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/strided_slice_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/strided_slice_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/Shape&quot;\\n  input: &quot;^optimizer/gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/b_sync&quot;\\n  op: &quot;ControlTrigger&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_2&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/strided_slice/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/strided_slice/stack&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_2&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_3&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_3&quot;\\n  input: &quot;loss_function/while/while/strided_slice/stack&quot;\\n  input: &quot;^optimizer/gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_1/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_1/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/strided_slice/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc_2&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/strided_slice/stack_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_4&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_5&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPushV2_2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Enter_5&quot;\\n  input: &quot;loss_function/while/while/strided_slice/stack_1&quot;\\n  input: &quot;^optimizer/gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/f_acc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/StackPopV2_2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad/Const_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/ReduceLogSumExp/Sum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/ReduceLogSumExp/Sum&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/Enter_1&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Sum&quot;\\n  input: &quot;^optimizer/gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal/StackPopV2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/control_dependency&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Shape&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/b_acc&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice_grad/StridedSliceGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/add/Const&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/add/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/range/start&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Size&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/range&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/mod&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/DynamicStitch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Log_grad/mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/AddN_3&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_3/Enter_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_4_grad/StridedSliceGrad&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/strided_slice/Enter_grad/b_acc_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 4\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/strided_slice_8_grad/StridedSliceGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/stack/1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Rank&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/stack/1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/Slice/begin&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/Slice/begin&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/Enter&quot;\\n  input: &quot;loss_function/while/Slice/begin&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss_function/while/Slice/Enter&quot;\\n  input: &quot;^loss_function/while/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/Slice_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/Slice_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Shape_1&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/Slice_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/f_acc_1&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Const_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/Slice_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPushV2_1&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/Enter_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Shape&quot;\\n  input: &quot;^optimizer/gradients/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2_1&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2_1/Enter&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/StackPopV2_1/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub/f_acc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape/StackPopV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/sub_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/stack&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Reshape_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice_grad/Pad&quot;\\n  op: &quot;Pad&quot;\\n  input: &quot;optimizer/gradients/AddN_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tpaddings&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sum_grad/Tile&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/ReduceLogSumExp/Exp&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/f_acc&quot;\\n  op: &quot;StackV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/while/while/ReduceLogSumExp/Exp&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;stack_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPushV2&quot;\\n  op: &quot;StackPushV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/Enter_1&quot;\\n  input: &quot;loss_function/while/while/ReduceLogSumExp/Exp&quot;\\n  input: &quot;^optimizer/gradients/Add_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;swap_memory&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2&quot;\\n  op: &quot;StackPopV2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2/Enter_1&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;elem_type&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2/Enter&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/f_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2/Enter_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul/StackPopV2/Enter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_RESOURCE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;neural_network/layer_2_full_cn/activation_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/b_acc&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/b_acc_1&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/b_acc&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice_grad/Pad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/b_acc_2&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Exp_grad/mul&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Neg&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/AddN_4&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Reshape_grad/Reshape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Reshape_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Sum&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/Slice/Enter_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Sum_1&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape_1&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/control_dependency&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;neural_network/layer_1_full_cn/activation_1&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul_1&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/activation_1_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/tuple/control_dependency&quot;\\n  input: &quot;neural_network/layer_1_full_cn/activation_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 300\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/activation_1_grad/ReluGrad&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Sum&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/activation_1_grad/ReluGrad&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Sum_1&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape_1&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/tuple/control_dependency&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/ReduceLogSumExp/Sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;inputs&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul_1&quot;\\n  input: &quot;^optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/b_count_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Rank&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Const&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Rank&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_3&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_4&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_5&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_6&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_7&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_8&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_9&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_10&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_11&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_12&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_13&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_14&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_15&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_16&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\021\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_4&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_5&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_6&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_7&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_8&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_9&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_10&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_11&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_12&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_13&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_14&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_15&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Shape_16&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 17\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice/begin/1&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/mod&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice/begin/1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice/size&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\377\\\\377\\\\377\\\\377&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/stack&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice/begin&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n  op: &quot;SplitV&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/Squeeze&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/mod&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlen&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 17\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:1&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:2&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:3&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:4&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_5&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:5&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_6&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:6&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_7&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:7&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_8&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:8&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_9&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:9&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_10&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:10&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_11&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:11&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_12&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:12&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_13&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:13&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_14&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:14&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_15&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:15&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_16&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/split:16&quot;\\n  input: &quot;^optimizer/gradients/loss_function/while/while/concat_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/AddN_5&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_1_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while_1/strided_slice_2/Enter_grad/b_acc_3&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc_1&quot;\\n  op: &quot;Enter&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;frame_name&quot;\\n    value {\\n      s: &quot;optimizer/gradients/loss_function/while/while_context&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;is_constant&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;parallel_iterations&quot;\\n    value {\\n      i: 10\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc_2&quot;\\n  op: &quot;Merge&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/NextIteration&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/Switch&quot;\\n  op: &quot;Switch&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc_2&quot;\\n  input: &quot;optimizer/gradients/b_count_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/Switch:1&quot;\\n  input: &quot;optimizer/gradients/AddN_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc_3&quot;\\n  op: &quot;Exit&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/Switch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/AddN_6&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_1&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_2&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_3&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_4&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_5&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_6&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_7&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_8&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_9&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_10&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_11&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_12&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_13&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_14&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_15&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/concat_grad/tuple/control_dependency_16&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 17\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@optimizer/gradients/loss_function/while/while/concat_grad/split&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^optimizer/gradients/Sub_2&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 17\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;optimizer/gradients/AddN_6&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/gradients/loss_function/while/while/Switch_1_grad_1/NextIteration&quot;\\n  op: &quot;NextIteration&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/Reshape_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta1_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta1_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta1_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/beta1_power&quot;\\n  input: &quot;optimizer/beta1_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta1_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/beta1_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta2_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta2_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta2_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/beta2_power&quot;\\n  input: &quot;optimizer/beta2_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/beta2_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/beta2_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\016\\\\001\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 270\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\016\\\\001\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 270\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\021\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_DOUBLE\\n        tensor_shape {\\n          dim {\\n            size: 17\\n          }\\n        }\\n        double_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 17\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993922529e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/learning_rate&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_3&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_4&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_5&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/epsilon&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_2&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_3&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_4&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/Cast_5&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/weight_mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/learning_rate&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_3&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_4&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_5&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/epsilon&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_2&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_3&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_4&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/Cast_5&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_1_full_cn/biases_add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/learning_rate&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_3&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_4&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_5&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/epsilon&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_2&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_3&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_4&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/Cast_5&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/weight_mul_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/learning_rate&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_3&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_4&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_5&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/epsilon&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_1&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_2&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_3&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_4&quot;\\n  input: &quot;optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/Cast_5&quot;\\n  input: &quot;optimizer/gradients/neural_network/layer_2_full_cn/biases_add_2_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/learning_rate&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_3&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_4&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_5&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/epsilon&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;loss_function/transition_weights/start_weights&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_1&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_2&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_3&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_4&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/start_weights/Cast_5&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/add_4/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/learning_rate&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_3&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_4&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_5&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/epsilon&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;loss_function/transition_weights/trans_weights&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_1&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_2&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_3&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_4&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/trans_weights/Cast_5&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/while/add/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/learning_rate&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_3&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_4&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_5&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;optimizer/Adam/epsilon&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;loss_function/transition_weights/final_weights&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_1&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_2&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_3&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_4&quot;\\n  input: &quot;optimizer/Adam/update_loss_function/transition_weights/final_weights/Cast_5&quot;\\n  input: &quot;optimizer/gradients/loss_function/while/strided_slice_10/Enter_grad/b_acc_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;optimizer/beta1_power/read&quot;\\n  input: &quot;optimizer/Adam/beta1&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/final_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/start_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/trans_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/beta1_power&quot;\\n  input: &quot;optimizer/Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;optimizer/beta2_power/read&quot;\\n  input: &quot;optimizer/Adam/beta2&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/final_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/start_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/trans_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/beta2_power&quot;\\n  input: &quot;optimizer/Adam/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;optimizer/Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^optimizer/Adam/Assign&quot;\\n  input: &quot;^optimizer/Adam/Assign_1&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/final_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/start_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_loss_function/transition_weights/trans_weights/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_1_full_cn/biases_1/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_1_full_cn/weight_1/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_2_full_cn/biases_2/ApplyAdam&quot;\\n  input: &quot;^optimizer/Adam/update_neural_network/layer_2_full_cn/weight_2/ApplyAdam&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^loss_function/transition_weights/final_weights/Assign&quot;\\n  input: &quot;^loss_function/transition_weights/start_weights/Assign&quot;\\n  input: &quot;^loss_function/transition_weights/trans_weights/Assign&quot;\\n  input: &quot;^neural_network/layer_1_full_cn/biases_1/Assign&quot;\\n  input: &quot;^neural_network/layer_1_full_cn/weight_1/Assign&quot;\\n  input: &quot;^neural_network/layer_2_full_cn/biases_2/Assign&quot;\\n  input: &quot;^neural_network/layer_2_full_cn/weight_2/Assign&quot;\\n  input: &quot;^optimizer/beta1_power/Assign&quot;\\n  input: &quot;^optimizer/beta2_power/Assign&quot;\\n  input: &quot;^optimizer/loss_function/transition_weights/final_weights/Adam/Assign&quot;\\n  input: &quot;^optimizer/loss_function/transition_weights/final_weights/Adam_1/Assign&quot;\\n  input: &quot;^optimizer/loss_function/transition_weights/start_weights/Adam/Assign&quot;\\n  input: &quot;^optimizer/loss_function/transition_weights/start_weights/Adam_1/Assign&quot;\\n  input: &quot;^optimizer/loss_function/transition_weights/trans_weights/Adam/Assign&quot;\\n  input: &quot;^optimizer/loss_function/transition_weights/trans_weights/Adam_1/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_1_full_cn/biases_1/Adam/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_1_full_cn/weight_1/Adam/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_2_full_cn/biases_2/Adam/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_2_full_cn/weight_2/Adam/Assign&quot;\\n  input: &quot;^optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/filename/input&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/filename&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename/input&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;PlaceholderWithDefault&quot;\\n  input: &quot;save/filename&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 23\\n          }\\n        }\\n        string_val: &quot;loss_function/transition_weights/final_weights&quot;\\n        string_val: &quot;loss_function/transition_weights/start_weights&quot;\\n        string_val: &quot;loss_function/transition_weights/trans_weights&quot;\\n        string_val: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n        string_val: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n        string_val: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n        string_val: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n        string_val: &quot;optimizer/beta1_power&quot;\\n        string_val: &quot;optimizer/beta2_power&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 23\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;loss_function/transition_weights/final_weights&quot;\\n  input: &quot;loss_function/transition_weights/start_weights&quot;\\n  input: &quot;loss_function/transition_weights/trans_weights&quot;\\n  input: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n  input: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n  input: &quot;optimizer/beta1_power&quot;\\n  input: &quot;optimizer/beta2_power&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 23\\n          }\\n        }\\n        string_val: &quot;loss_function/transition_weights/final_weights&quot;\\n        string_val: &quot;loss_function/transition_weights/start_weights&quot;\\n        string_val: &quot;loss_function/transition_weights/trans_weights&quot;\\n        string_val: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n        string_val: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n        string_val: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n        string_val: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n        string_val: &quot;optimizer/beta1_power&quot;\\n        string_val: &quot;optimizer/beta2_power&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n        string_val: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n        string_val: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 23\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n        type: DT_DOUBLE\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;loss_function/transition_weights/final_weights&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;loss_function/transition_weights/start_weights&quot;\\n  input: &quot;save/RestoreV2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;loss_function/transition_weights/trans_weights&quot;\\n  input: &quot;save/RestoreV2:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_1_full_cn/biases_1&quot;\\n  input: &quot;save/RestoreV2:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_1_full_cn/weight_1&quot;\\n  input: &quot;save/RestoreV2:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_2_full_cn/biases_2&quot;\\n  input: &quot;save/RestoreV2:5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_6&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;neural_network/layer_2_full_cn/weight_2&quot;\\n  input: &quot;save/RestoreV2:6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_7&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/beta1_power&quot;\\n  input: &quot;save/RestoreV2:7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_8&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/beta2_power&quot;\\n  input: &quot;save/RestoreV2:8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_9&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam&quot;\\n  input: &quot;save/RestoreV2:9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_10&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/final_weights/Adam_1&quot;\\n  input: &quot;save/RestoreV2:10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/final_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_11&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam&quot;\\n  input: &quot;save/RestoreV2:11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_12&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/start_weights/Adam_1&quot;\\n  input: &quot;save/RestoreV2:12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/start_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_13&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam&quot;\\n  input: &quot;save/RestoreV2:13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_14&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/loss_function/transition_weights/trans_weights/Adam_1&quot;\\n  input: &quot;save/RestoreV2:14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss_function/transition_weights/trans_weights&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_15&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam&quot;\\n  input: &quot;save/RestoreV2:15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_16&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/biases_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2:16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/biases_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_17&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam&quot;\\n  input: &quot;save/RestoreV2:17&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_18&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_1_full_cn/weight_1/Adam_1&quot;\\n  input: &quot;save/RestoreV2:18&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_1_full_cn/weight_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_19&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam&quot;\\n  input: &quot;save/RestoreV2:19&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_20&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/biases_2/Adam_1&quot;\\n  input: &quot;save/RestoreV2:20&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/biases_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_21&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam&quot;\\n  input: &quot;save/RestoreV2:21&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_22&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;optimizer/neural_network/layer_2_full_cn/weight_2/Adam_1&quot;\\n  input: &quot;save/RestoreV2:22&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@neural_network/layer_2_full_cn/weight_2&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_10&quot;\\n  input: &quot;^save/Assign_11&quot;\\n  input: &quot;^save/Assign_12&quot;\\n  input: &quot;^save/Assign_13&quot;\\n  input: &quot;^save/Assign_14&quot;\\n  input: &quot;^save/Assign_15&quot;\\n  input: &quot;^save/Assign_16&quot;\\n  input: &quot;^save/Assign_17&quot;\\n  input: &quot;^save/Assign_18&quot;\\n  input: &quot;^save/Assign_19&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_20&quot;\\n  input: &quot;^save/Assign_21&quot;\\n  input: &quot;^save/Assign_22&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n  input: &quot;^save/Assign_6&quot;\\n  input: &quot;^save/Assign_7&quot;\\n  input: &quot;^save/Assign_8&quot;\\n  input: &quot;^save/Assign_9&quot;\\n}\\n';\n",
       "              }\n",
       "            </script>\n",
       "            <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "            <div style=&quot;height:600px&quot;>\n",
       "              <tf-graph-basic id=&quot;graph0.9355421351557515&quot;></tf-graph-basic>\n",
       "            </div>\n",
       "        \"></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with SennaNER(model_details_dict) as senna_ner:\n",
    "    \n",
    "    senna_ner.show_graph()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041\n",
      "3250\n",
      "3453\n"
     ]
    }
   ],
   "source": [
    "for key in input_data:\n",
    "    print(len(input_data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1c82e6a1e00c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mSennaNER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_details_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msenna_ner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msenna_ner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/research/senna-replica/senna_ner.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, batch_size, display_step, num_training_epochs)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mepoch_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_trained_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_wdvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/research/senna-replica/senna_ner.py\u001b[0m in \u001b[0;36mload_wdvec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwdvec_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m             \u001b[0mnumpy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# word-level\n",
    "with SennaNER(model_details_dict) as senna_ner:\n",
    "    \n",
    "    senna_ner.train_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 88.687\n",
      "Time elapsed since the last checkpoint : 88.689\n",
      "Time elapsed for the last epoc training: 79.949\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.968\n",
      "Cumulative testa loss over the last epoc: 1.384\n",
      "Cumulative testb loss over the last epoc: 1.469\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.978\n",
      "Cumulative testa accuracy over the last epoc: 0.972\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.912\n",
      "Cumulative testa precision over the last epoc: 0.892\n",
      "Cumulative testb precision over the last epoc: 0.862\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.88\n",
      "Cumulative testa recall over the last epoc: 0.858\n",
      "Cumulative testb recall over the last epoc: 0.833\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.896\n",
      "Cumulative testa f1_score over the last epoc: 0.875\n",
      "Cumulative testb f1_score over the last epoc: 0.848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 161.126\n",
      "Time elapsed since the last checkpoint : 72.433\n",
      "Time elapsed for the last epoc training: 72.076\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.583\n",
      "Cumulative testa loss over the last epoc: 1.142\n",
      "Cumulative testb loss over the last epoc: 1.373\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.986\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.937\n",
      "Cumulative testa precision over the last epoc: 0.9\n",
      "Cumulative testb precision over the last epoc: 0.86\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.93\n",
      "Cumulative testa recall over the last epoc: 0.888\n",
      "Cumulative testb recall over the last epoc: 0.859\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.933\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.86\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 235.807\n",
      "Time elapsed since the last checkpoint : 74.68\n",
      "Time elapsed for the last epoc training: 74.549\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.444\n",
      "Cumulative testa loss over the last epoc: 1.144\n",
      "Cumulative testb loss over the last epoc: 1.424\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.99\n",
      "Cumulative testa accuracy over the last epoc: 0.975\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.949\n",
      "Cumulative testa precision over the last epoc: 0.893\n",
      "Cumulative testb precision over the last epoc: 0.852\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.946\n",
      "Cumulative testa recall over the last epoc: 0.886\n",
      "Cumulative testb recall over the last epoc: 0.848\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.948\n",
      "Cumulative testa f1_score over the last epoc: 0.889\n",
      "Cumulative testb f1_score over the last epoc: 0.85\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 311.46\n",
      "Time elapsed since the last checkpoint : 75.648\n",
      "Time elapsed for the last epoc training: 75.493\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.341\n",
      "Cumulative testa loss over the last epoc: 1.148\n",
      "Cumulative testb loss over the last epoc: 1.49\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.991\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.959\n",
      "Cumulative testa precision over the last epoc: 0.898\n",
      "Cumulative testb precision over the last epoc: 0.854\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.957\n",
      "Cumulative testa recall over the last epoc: 0.887\n",
      "Cumulative testb recall over the last epoc: 0.854\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.958\n",
      "Cumulative testa f1_score over the last epoc: 0.892\n",
      "Cumulative testb f1_score over the last epoc: 0.854\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 389.054\n",
      "Time elapsed since the last checkpoint : 77.583\n",
      "Time elapsed for the last epoc training: 77.434\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.222\n",
      "Cumulative testa loss over the last epoc: 1.144\n",
      "Cumulative testb loss over the last epoc: 1.42\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.994\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.97\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.976\n",
      "Cumulative testa precision over the last epoc: 0.904\n",
      "Cumulative testb precision over the last epoc: 0.872\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.97\n",
      "Cumulative testa recall over the last epoc: 0.888\n",
      "Cumulative testb recall over the last epoc: 0.86\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.973\n",
      "Cumulative testa f1_score over the last epoc: 0.896\n",
      "Cumulative testb f1_score over the last epoc: 0.866\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 486.249\n",
      "Time elapsed since the last checkpoint : 97.189\n",
      "Time elapsed for the last epoc training: 96.982\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.169\n",
      "Cumulative testa loss over the last epoc: 1.12\n",
      "Cumulative testb loss over the last epoc: 1.43\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.98\n",
      "Cumulative testb accuracy over the last epoc: 0.971\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.981\n",
      "Cumulative testa precision over the last epoc: 0.916\n",
      "Cumulative testb precision over the last epoc: 0.875\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.976\n",
      "Cumulative testa recall over the last epoc: 0.899\n",
      "Cumulative testb recall over the last epoc: 0.864\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.979\n",
      "Cumulative testa f1_score over the last epoc: 0.908\n",
      "Cumulative testb f1_score over the last epoc: 0.87\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 612.715\n",
      "Time elapsed since the last checkpoint : 126.463\n",
      "Time elapsed for the last epoc training: 126.116\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.14\n",
      "Cumulative testa loss over the last epoc: 1.196\n",
      "Cumulative testb loss over the last epoc: 1.579\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.98\n",
      "Cumulative testb accuracy over the last epoc: 0.971\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.984\n",
      "Cumulative testa precision over the last epoc: 0.912\n",
      "Cumulative testb precision over the last epoc: 0.87\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.982\n",
      "Cumulative testa recall over the last epoc: 0.906\n",
      "Cumulative testb recall over the last epoc: 0.869\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.983\n",
      "Cumulative testa f1_score over the last epoc: 0.909\n",
      "Cumulative testb f1_score over the last epoc: 0.869\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 721.867\n",
      "Time elapsed since the last checkpoint : 109.149\n",
      "Time elapsed for the last epoc training: 108.75\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.142\n",
      "Cumulative testa loss over the last epoc: 1.279\n",
      "Cumulative testb loss over the last epoc: 1.779\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.983\n",
      "Cumulative testa precision over the last epoc: 0.911\n",
      "Cumulative testb precision over the last epoc: 0.861\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.983\n",
      "Cumulative testa recall over the last epoc: 0.9\n",
      "Cumulative testb recall over the last epoc: 0.86\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.983\n",
      "Cumulative testa f1_score over the last epoc: 0.905\n",
      "Cumulative testb f1_score over the last epoc: 0.86\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 9 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 805.531\n",
      "Time elapsed since the last checkpoint : 83.661\n",
      "Time elapsed for the last epoc training: 83.385\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.129\n",
      "Cumulative testa loss over the last epoc: 1.384\n",
      "Cumulative testb loss over the last epoc: 1.874\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.986\n",
      "Cumulative testa precision over the last epoc: 0.912\n",
      "Cumulative testb precision over the last epoc: 0.866\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.981\n",
      "Cumulative testa recall over the last epoc: 0.887\n",
      "Cumulative testb recall over the last epoc: 0.851\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.984\n",
      "Cumulative testa f1_score over the last epoc: 0.899\n",
      "Cumulative testb f1_score over the last epoc: 0.859\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 897.384\n",
      "Time elapsed since the last checkpoint : 91.852\n",
      "Time elapsed for the last epoc training: 91.692\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.108\n",
      "Cumulative testa loss over the last epoc: 1.401\n",
      "Cumulative testb loss over the last epoc: 1.826\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.971\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.986\n",
      "Cumulative testa precision over the last epoc: 0.905\n",
      "Cumulative testb precision over the last epoc: 0.875\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.984\n",
      "Cumulative testa recall over the last epoc: 0.892\n",
      "Cumulative testb recall over the last epoc: 0.867\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.985\n",
      "Cumulative testa f1_score over the last epoc: 0.898\n",
      "Cumulative testb f1_score over the last epoc: 0.871\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 11 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 988.97\n",
      "Time elapsed since the last checkpoint : 91.585\n",
      "Time elapsed for the last epoc training: 91.326\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.099\n",
      "Cumulative testa loss over the last epoc: 1.512\n",
      "Cumulative testb loss over the last epoc: 1.901\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.979\n",
      "Cumulative testb accuracy over the last epoc: 0.969\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.91\n",
      "Cumulative testb precision over the last epoc: 0.867\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.987\n",
      "Cumulative testa recall over the last epoc: 0.899\n",
      "Cumulative testb recall over the last epoc: 0.862\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.988\n",
      "Cumulative testa f1_score over the last epoc: 0.904\n",
      "Cumulative testb f1_score over the last epoc: 0.865\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 12 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1070.132\n",
      "Time elapsed since the last checkpoint : 81.158\n",
      "Time elapsed for the last epoc training: 80.826\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.117\n",
      "Cumulative testa loss over the last epoc: 1.531\n",
      "Cumulative testb loss over the last epoc: 2.119\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.979\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.985\n",
      "Cumulative testa precision over the last epoc: 0.905\n",
      "Cumulative testb precision over the last epoc: 0.858\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.982\n",
      "Cumulative testa recall over the last epoc: 0.896\n",
      "Cumulative testb recall over the last epoc: 0.853\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.984\n",
      "Cumulative testa f1_score over the last epoc: 0.901\n",
      "Cumulative testb f1_score over the last epoc: 0.855\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 13 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1155.448\n",
      "Time elapsed since the last checkpoint : 85.312\n",
      "Time elapsed for the last epoc training: 85.184\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.148\n",
      "Cumulative testa loss over the last epoc: 1.742\n",
      "Cumulative testb loss over the last epoc: 2.267\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.982\n",
      "Cumulative testa precision over the last epoc: 0.906\n",
      "Cumulative testb precision over the last epoc: 0.857\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.981\n",
      "Cumulative testa recall over the last epoc: 0.891\n",
      "Cumulative testb recall over the last epoc: 0.852\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.981\n",
      "Cumulative testa f1_score over the last epoc: 0.898\n",
      "Cumulative testb f1_score over the last epoc: 0.855\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 14 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1232.573\n",
      "Time elapsed since the last checkpoint : 77.122\n",
      "Time elapsed for the last epoc training: 76.994\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.161\n",
      "Cumulative testa loss over the last epoc: 1.913\n",
      "Cumulative testb loss over the last epoc: 2.384\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.975\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.979\n",
      "Cumulative testa precision over the last epoc: 0.888\n",
      "Cumulative testb precision over the last epoc: 0.847\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.978\n",
      "Cumulative testa recall over the last epoc: 0.878\n",
      "Cumulative testb recall over the last epoc: 0.846\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.978\n",
      "Cumulative testa f1_score over the last epoc: 0.883\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 15 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1307.591\n",
      "Time elapsed since the last checkpoint : 75.013\n",
      "Time elapsed for the last epoc training: 74.825\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.132\n",
      "Cumulative testa loss over the last epoc: 1.876\n",
      "Cumulative testb loss over the last epoc: 2.324\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.979\n",
      "Cumulative testb accuracy over the last epoc: 0.969\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.984\n",
      "Cumulative testa precision over the last epoc: 0.906\n",
      "Cumulative testb precision over the last epoc: 0.866\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.983\n",
      "Cumulative testa recall over the last epoc: 0.894\n",
      "Cumulative testb recall over the last epoc: 0.861\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.984\n",
      "Cumulative testa f1_score over the last epoc: 0.9\n",
      "Cumulative testb f1_score over the last epoc: 0.864\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 16 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1384.741\n",
      "Time elapsed since the last checkpoint : 77.152\n",
      "Time elapsed for the last epoc training: 77.028\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.146\n",
      "Cumulative testa loss over the last epoc: 2.031\n",
      "Cumulative testb loss over the last epoc: 2.37\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.98\n",
      "Cumulative testa precision over the last epoc: 0.901\n",
      "Cumulative testb precision over the last epoc: 0.854\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.979\n",
      "Cumulative testa recall over the last epoc: 0.888\n",
      "Cumulative testb recall over the last epoc: 0.853\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.979\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.853\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 17 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1467.893\n",
      "Time elapsed since the last checkpoint : 83.146\n",
      "Time elapsed for the last epoc training: 82.967\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.112\n",
      "Cumulative testa loss over the last epoc: 1.983\n",
      "Cumulative testb loss over the last epoc: 2.44\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.969\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.986\n",
      "Cumulative testa precision over the last epoc: 0.9\n",
      "Cumulative testb precision over the last epoc: 0.863\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.987\n",
      "Cumulative testa recall over the last epoc: 0.896\n",
      "Cumulative testb recall over the last epoc: 0.863\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.986\n",
      "Cumulative testa f1_score over the last epoc: 0.898\n",
      "Cumulative testb f1_score over the last epoc: 0.863\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 18 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1559.54\n",
      "Time elapsed since the last checkpoint : 91.643\n",
      "Time elapsed for the last epoc training: 91.513\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.072\n",
      "Cumulative testa loss over the last epoc: 1.918\n",
      "Cumulative testb loss over the last epoc: 2.528\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.979\n",
      "Cumulative testb accuracy over the last epoc: 0.97\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.908\n",
      "Cumulative testb precision over the last epoc: 0.872\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.99\n",
      "Cumulative testa recall over the last epoc: 0.896\n",
      "Cumulative testb recall over the last epoc: 0.863\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.991\n",
      "Cumulative testa f1_score over the last epoc: 0.902\n",
      "Cumulative testb f1_score over the last epoc: 0.867\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 19 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1630.978\n",
      "Time elapsed since the last checkpoint : 71.432\n",
      "Time elapsed for the last epoc training: 71.244\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.093\n",
      "Cumulative testa loss over the last epoc: 2.076\n",
      "Cumulative testb loss over the last epoc: 2.636\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.99\n",
      "Cumulative testa precision over the last epoc: 0.907\n",
      "Cumulative testb precision over the last epoc: 0.865\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.988\n",
      "Cumulative testa recall over the last epoc: 0.888\n",
      "Cumulative testb recall over the last epoc: 0.855\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.989\n",
      "Cumulative testa f1_score over the last epoc: 0.897\n",
      "Cumulative testb f1_score over the last epoc: 0.86\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 20 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1709.046\n",
      "Time elapsed since the last checkpoint : 78.066\n",
      "Time elapsed for the last epoc training: 77.902\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.096\n",
      "Cumulative testa loss over the last epoc: 2.228\n",
      "Cumulative testb loss over the last epoc: 2.696\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.969\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.916\n",
      "Cumulative testb precision over the last epoc: 0.873\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.985\n",
      "Cumulative testa recall over the last epoc: 0.882\n",
      "Cumulative testb recall over the last epoc: 0.849\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.988\n",
      "Cumulative testa f1_score over the last epoc: 0.898\n",
      "Cumulative testb f1_score over the last epoc: 0.861\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 21 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1792.431\n",
      "Time elapsed since the last checkpoint : 83.382\n",
      "Time elapsed for the last epoc training: 83.12\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.1\n",
      "Cumulative testa loss over the last epoc: 2.314\n",
      "Cumulative testb loss over the last epoc: 2.824\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.969\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.987\n",
      "Cumulative testa precision over the last epoc: 0.898\n",
      "Cumulative testb precision over the last epoc: 0.858\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.987\n",
      "Cumulative testa recall over the last epoc: 0.889\n",
      "Cumulative testb recall over the last epoc: 0.855\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 22 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1869.45\n",
      "Time elapsed since the last checkpoint : 77.014\n",
      "Time elapsed for the last epoc training: 76.73\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.108\n",
      "Cumulative testa loss over the last epoc: 2.582\n",
      "Cumulative testb loss over the last epoc: 2.933\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.988\n",
      "Cumulative testa precision over the last epoc: 0.903\n",
      "Cumulative testb precision over the last epoc: 0.864\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.985\n",
      "Cumulative testa recall over the last epoc: 0.886\n",
      "Cumulative testb recall over the last epoc: 0.852\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.858\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 23 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 1951.214\n",
      "Time elapsed since the last checkpoint : 81.76\n",
      "Time elapsed for the last epoc training: 81.593\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.107\n",
      "Cumulative testa loss over the last epoc: 2.456\n",
      "Cumulative testb loss over the last epoc: 3.189\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.987\n",
      "Cumulative testa precision over the last epoc: 0.9\n",
      "Cumulative testb precision over the last epoc: 0.856\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.987\n",
      "Cumulative testa recall over the last epoc: 0.893\n",
      "Cumulative testb recall over the last epoc: 0.859\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.897\n",
      "Cumulative testb f1_score over the last epoc: 0.858\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 24 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2035.604\n",
      "Time elapsed since the last checkpoint : 84.385\n",
      "Time elapsed for the last epoc training: 84.177\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.205\n",
      "Cumulative testa loss over the last epoc: 3.038\n",
      "Cumulative testb loss over the last epoc: 3.407\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.995\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.981\n",
      "Cumulative testa precision over the last epoc: 0.898\n",
      "Cumulative testb precision over the last epoc: 0.853\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.979\n",
      "Cumulative testa recall over the last epoc: 0.882\n",
      "Cumulative testb recall over the last epoc: 0.847\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.98\n",
      "Cumulative testa f1_score over the last epoc: 0.89\n",
      "Cumulative testb f1_score over the last epoc: 0.85\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 25 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2110.507\n",
      "Time elapsed since the last checkpoint : 74.9\n",
      "Time elapsed for the last epoc training: 74.739\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.129\n",
      "Cumulative testa loss over the last epoc: 2.752\n",
      "Cumulative testb loss over the last epoc: 3.326\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.986\n",
      "Cumulative testa precision over the last epoc: 0.901\n",
      "Cumulative testb precision over the last epoc: 0.86\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.984\n",
      "Cumulative testa recall over the last epoc: 0.885\n",
      "Cumulative testb recall over the last epoc: 0.852\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.985\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.856\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 26 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2191.458\n",
      "Time elapsed since the last checkpoint : 80.948\n",
      "Time elapsed for the last epoc training: 80.759\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.08\n",
      "Cumulative testa loss over the last epoc: 2.686\n",
      "Cumulative testb loss over the last epoc: 3.189\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.99\n",
      "Cumulative testa precision over the last epoc: 0.898\n",
      "Cumulative testb precision over the last epoc: 0.86\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.99\n",
      "Cumulative testa recall over the last epoc: 0.888\n",
      "Cumulative testb recall over the last epoc: 0.859\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.99\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.86\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 27 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2270.002\n",
      "Time elapsed since the last checkpoint : 78.539\n",
      "Time elapsed for the last epoc training: 78.38\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.044\n",
      "Cumulative testa loss over the last epoc: 2.61\n",
      "Cumulative testb loss over the last epoc: 3.225\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.999\n",
      "Cumulative testa accuracy over the last epoc: 0.979\n",
      "Cumulative testb accuracy over the last epoc: 0.97\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.995\n",
      "Cumulative testa precision over the last epoc: 0.907\n",
      "Cumulative testb precision over the last epoc: 0.866\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.994\n",
      "Cumulative testa recall over the last epoc: 0.895\n",
      "Cumulative testb recall over the last epoc: 0.86\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.994\n",
      "Cumulative testa f1_score over the last epoc: 0.901\n",
      "Cumulative testb f1_score over the last epoc: 0.863\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 28 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2344.316\n",
      "Time elapsed since the last checkpoint : 74.309\n",
      "Time elapsed for the last epoc training: 74.162\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.051\n",
      "Cumulative testa loss over the last epoc: 2.906\n",
      "Cumulative testb loss over the last epoc: 3.278\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.999\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.97\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.909\n",
      "Cumulative testb precision over the last epoc: 0.869\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.993\n",
      "Cumulative testa recall over the last epoc: 0.892\n",
      "Cumulative testb recall over the last epoc: 0.858\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.993\n",
      "Cumulative testa f1_score over the last epoc: 0.9\n",
      "Cumulative testb f1_score over the last epoc: 0.864\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 29 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2432.408\n",
      "Time elapsed since the last checkpoint : 88.092\n",
      "Time elapsed for the last epoc training: 87.892\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.069\n",
      "Cumulative testa loss over the last epoc: 2.82\n",
      "Cumulative testb loss over the last epoc: 3.516\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.902\n",
      "Cumulative testb precision over the last epoc: 0.855\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.993\n",
      "Cumulative testa recall over the last epoc: 0.894\n",
      "Cumulative testb recall over the last epoc: 0.856\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.992\n",
      "Cumulative testa f1_score over the last epoc: 0.898\n",
      "Cumulative testb f1_score over the last epoc: 0.855\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 30 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2517.669\n",
      "Time elapsed since the last checkpoint : 85.256\n",
      "Time elapsed for the last epoc training: 85.067\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.07\n",
      "Cumulative testa loss over the last epoc: 2.901\n",
      "Cumulative testb loss over the last epoc: 3.735\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.999\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.903\n",
      "Cumulative testb precision over the last epoc: 0.854\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.991\n",
      "Cumulative testa recall over the last epoc: 0.89\n",
      "Cumulative testb recall over the last epoc: 0.855\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.991\n",
      "Cumulative testa f1_score over the last epoc: 0.896\n",
      "Cumulative testb f1_score over the last epoc: 0.854\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 31 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2593.675\n",
      "Time elapsed since the last checkpoint : 76.0\n",
      "Time elapsed for the last epoc training: 75.685\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.11\n",
      "Cumulative testa loss over the last epoc: 2.956\n",
      "Cumulative testb loss over the last epoc: 3.908\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.985\n",
      "Cumulative testa precision over the last epoc: 0.893\n",
      "Cumulative testb precision over the last epoc: 0.842\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.99\n",
      "Cumulative testa recall over the last epoc: 0.889\n",
      "Cumulative testb recall over the last epoc: 0.853\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.891\n",
      "Cumulative testb f1_score over the last epoc: 0.848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 32 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2667.567\n",
      "Time elapsed since the last checkpoint : 73.891\n",
      "Time elapsed for the last epoc training: 73.741\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.064\n",
      "Cumulative testa loss over the last epoc: 3.066\n",
      "Cumulative testb loss over the last epoc: 3.766\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.999\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.969\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.906\n",
      "Cumulative testb precision over the last epoc: 0.864\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.992\n",
      "Cumulative testa recall over the last epoc: 0.889\n",
      "Cumulative testb recall over the last epoc: 0.856\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.993\n",
      "Cumulative testa f1_score over the last epoc: 0.897\n",
      "Cumulative testb f1_score over the last epoc: 0.86\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 33 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2743.135\n",
      "Time elapsed since the last checkpoint : 75.566\n",
      "Time elapsed for the last epoc training: 75.445\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.082\n",
      "Cumulative testa loss over the last epoc: 2.961\n",
      "Cumulative testb loss over the last epoc: 3.715\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.901\n",
      "Cumulative testb precision over the last epoc: 0.863\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.989\n",
      "Cumulative testa recall over the last epoc: 0.884\n",
      "Cumulative testb recall over the last epoc: 0.857\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.99\n",
      "Cumulative testa f1_score over the last epoc: 0.892\n",
      "Cumulative testb f1_score over the last epoc: 0.86\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 34 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 2838.762\n",
      "Time elapsed since the last checkpoint : 95.623\n",
      "Time elapsed for the last epoc training: 95.403\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.104\n",
      "Cumulative testa loss over the last epoc: 3.217\n",
      "Cumulative testb loss over the last epoc: 3.894\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.904\n",
      "Cumulative testb precision over the last epoc: 0.855\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.99\n",
      "Cumulative testa recall over the last epoc: 0.892\n",
      "Cumulative testb recall over the last epoc: 0.855\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.989\n",
      "Cumulative testa f1_score over the last epoc: 0.898\n",
      "Cumulative testb f1_score over the last epoc: 0.855\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-60f2da1c9642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     for item in senna_ner.var_list:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         print(item)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msenna_ner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/research/senna-replica/senna_ner.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, batch_size, display_step, num_training_epochs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;31m# Sample 'batch_size' number of sentences:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.permutation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# sentence-level\n",
    "with SennaNER(model_details_dict) as senna_ner:\n",
    "    \n",
    "#     for item in senna_ner.var_list:\n",
    "#         print(item)\n",
    "    senna_ner.train_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/smflores/Dropbox/research/senna-replica/senna_ner.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 29.107\n",
      "Time elapsed since the last checkpoint : 29.107\n",
      "Time elapsed for the last epoc training: 14.391\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.084\n",
      "Cumulative testa loss over the last epoc: 0.111\n",
      "Cumulative testb loss over the last epoc: 0.136\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.976\n",
      "Cumulative testa accuracy over the last epoc: 0.969\n",
      "Cumulative testb accuracy over the last epoc: 0.961\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.901\n",
      "Cumulative testa precision over the last epoc: 0.882\n",
      "Cumulative testb precision over the last epoc: 0.849\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.866\n",
      "Cumulative testa recall over the last epoc: 0.838\n",
      "Cumulative testb recall over the last epoc: 0.81\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.883\n",
      "Cumulative testa f1_score over the last epoc: 0.859\n",
      "Cumulative testb f1_score over the last epoc: 0.829\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 43.698\n",
      "Time elapsed since the last checkpoint : 14.587\n",
      "Time elapsed for the last epoc training: 14.426\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.056\n",
      "Cumulative testa loss over the last epoc: 0.101\n",
      "Cumulative testb loss over the last epoc: 0.125\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.984\n",
      "Cumulative testa accuracy over the last epoc: 0.974\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.937\n",
      "Cumulative testa precision over the last epoc: 0.9\n",
      "Cumulative testb precision over the last epoc: 0.867\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.909\n",
      "Cumulative testa recall over the last epoc: 0.858\n",
      "Cumulative testb recall over the last epoc: 0.829\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.923\n",
      "Cumulative testa f1_score over the last epoc: 0.879\n",
      "Cumulative testb f1_score over the last epoc: 0.848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 58.123\n",
      "Time elapsed since the last checkpoint : 14.423\n",
      "Time elapsed for the last epoc training: 14.363\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.04\n",
      "Cumulative testa loss over the last epoc: 0.092\n",
      "Cumulative testb loss over the last epoc: 0.131\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.989\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.962\n",
      "Cumulative testa precision over the last epoc: 0.917\n",
      "Cumulative testb precision over the last epoc: 0.878\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.936\n",
      "Cumulative testa recall over the last epoc: 0.876\n",
      "Cumulative testb recall over the last epoc: 0.838\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.949\n",
      "Cumulative testa f1_score over the last epoc: 0.896\n",
      "Cumulative testb f1_score over the last epoc: 0.858\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 70.486\n",
      "Time elapsed since the last checkpoint : 12.363\n",
      "Time elapsed for the last epoc training: 12.286\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.034\n",
      "Cumulative testa loss over the last epoc: 0.1\n",
      "Cumulative testb loss over the last epoc: 0.15\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.99\n",
      "Cumulative testa accuracy over the last epoc: 0.975\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.959\n",
      "Cumulative testa precision over the last epoc: 0.9\n",
      "Cumulative testb precision over the last epoc: 0.86\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.945\n",
      "Cumulative testa recall over the last epoc: 0.864\n",
      "Cumulative testb recall over the last epoc: 0.829\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.952\n",
      "Cumulative testa f1_score over the last epoc: 0.881\n",
      "Cumulative testb f1_score over the last epoc: 0.844\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 81.805\n",
      "Time elapsed since the last checkpoint : 11.317\n",
      "Time elapsed for the last epoc training: 11.266\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.027\n",
      "Cumulative testa loss over the last epoc: 0.101\n",
      "Cumulative testb loss over the last epoc: 0.15\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.993\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.968\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.975\n",
      "Cumulative testa precision over the last epoc: 0.918\n",
      "Cumulative testb precision over the last epoc: 0.881\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.953\n",
      "Cumulative testa recall over the last epoc: 0.872\n",
      "Cumulative testb recall over the last epoc: 0.833\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.964\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.856\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 6 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 92.385\n",
      "Time elapsed since the last checkpoint : 10.577\n",
      "Time elapsed for the last epoc training: 10.52\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.021\n",
      "Cumulative testa loss over the last epoc: 0.102\n",
      "Cumulative testb loss over the last epoc: 0.161\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.994\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.979\n",
      "Cumulative testa precision over the last epoc: 0.926\n",
      "Cumulative testb precision over the last epoc: 0.874\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.963\n",
      "Cumulative testa recall over the last epoc: 0.883\n",
      "Cumulative testb recall over the last epoc: 0.835\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.971\n",
      "Cumulative testa f1_score over the last epoc: 0.904\n",
      "Cumulative testb f1_score over the last epoc: 0.854\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 7 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 107.158\n",
      "Time elapsed since the last checkpoint : 14.775\n",
      "Time elapsed for the last epoc training: 14.719\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.017\n",
      "Cumulative testa loss over the last epoc: 0.111\n",
      "Cumulative testb loss over the last epoc: 0.174\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.995\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.984\n",
      "Cumulative testa precision over the last epoc: 0.926\n",
      "Cumulative testb precision over the last epoc: 0.879\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.968\n",
      "Cumulative testa recall over the last epoc: 0.879\n",
      "Cumulative testb recall over the last epoc: 0.836\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.976\n",
      "Cumulative testa f1_score over the last epoc: 0.902\n",
      "Cumulative testb f1_score over the last epoc: 0.857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 8 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 118.979\n",
      "Time elapsed since the last checkpoint : 11.817\n",
      "Time elapsed for the last epoc training: 11.732\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.02\n",
      "Cumulative testa loss over the last epoc: 0.125\n",
      "Cumulative testb loss over the last epoc: 0.185\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.994\n",
      "Cumulative testa accuracy over the last epoc: 0.975\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.978\n",
      "Cumulative testa precision over the last epoc: 0.912\n",
      "Cumulative testb precision over the last epoc: 0.876\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.959\n",
      "Cumulative testa recall over the last epoc: 0.86\n",
      "Cumulative testb recall over the last epoc: 0.831\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.968\n",
      "Cumulative testa f1_score over the last epoc: 0.885\n",
      "Cumulative testb f1_score over the last epoc: 0.853\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 9 of 50 completed.\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 129.833\n",
      "Time elapsed since the last checkpoint : 10.853\n",
      "Time elapsed for the last epoc training: 10.808\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.015\n",
      "Cumulative testa loss over the last epoc: 0.125\n",
      "Cumulative testb loss over the last epoc: 0.194\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.995\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.983\n",
      "Cumulative testa precision over the last epoc: 0.917\n",
      "Cumulative testb precision over the last epoc: 0.869\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.97\n",
      "Cumulative testa recall over the last epoc: 0.869\n",
      "Cumulative testb recall over the last epoc: 0.825\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.976\n",
      "Cumulative testa f1_score over the last epoc: 0.892\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 10 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 142.78\n",
      "Time elapsed since the last checkpoint : 12.946\n",
      "Time elapsed for the last epoc training: 12.901\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.012\n",
      "Cumulative testa loss over the last epoc: 0.132\n",
      "Cumulative testb loss over the last epoc: 0.201\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.988\n",
      "Cumulative testa precision over the last epoc: 0.921\n",
      "Cumulative testb precision over the last epoc: 0.877\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.978\n",
      "Cumulative testa recall over the last epoc: 0.873\n",
      "Cumulative testb recall over the last epoc: 0.835\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.983\n",
      "Cumulative testa f1_score over the last epoc: 0.896\n",
      "Cumulative testb f1_score over the last epoc: 0.855\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 11 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 154.081\n",
      "Time elapsed since the last checkpoint : 11.299\n",
      "Time elapsed for the last epoc training: 11.236\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.014\n",
      "Cumulative testa loss over the last epoc: 0.143\n",
      "Cumulative testb loss over the last epoc: 0.218\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.985\n",
      "Cumulative testa precision over the last epoc: 0.918\n",
      "Cumulative testb precision over the last epoc: 0.871\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.97\n",
      "Cumulative testa recall over the last epoc: 0.865\n",
      "Cumulative testb recall over the last epoc: 0.823\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.977\n",
      "Cumulative testa f1_score over the last epoc: 0.891\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 12 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 165.025\n",
      "Time elapsed since the last checkpoint : 10.943\n",
      "Time elapsed for the last epoc training: 10.89\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.013\n",
      "Cumulative testa loss over the last epoc: 0.154\n",
      "Cumulative testb loss over the last epoc: 0.232\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.984\n",
      "Cumulative testa precision over the last epoc: 0.913\n",
      "Cumulative testb precision over the last epoc: 0.878\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.975\n",
      "Cumulative testa recall over the last epoc: 0.866\n",
      "Cumulative testb recall over the last epoc: 0.83\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.98\n",
      "Cumulative testa f1_score over the last epoc: 0.889\n",
      "Cumulative testb f1_score over the last epoc: 0.853\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 13 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 175.482\n",
      "Time elapsed since the last checkpoint : 10.456\n",
      "Time elapsed for the last epoc training: 10.407\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.012\n",
      "Cumulative testa loss over the last epoc: 0.161\n",
      "Cumulative testb loss over the last epoc: 0.24\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.933\n",
      "Cumulative testb precision over the last epoc: 0.882\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.974\n",
      "Cumulative testa recall over the last epoc: 0.869\n",
      "Cumulative testb recall over the last epoc: 0.822\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.983\n",
      "Cumulative testa f1_score over the last epoc: 0.9\n",
      "Cumulative testb f1_score over the last epoc: 0.851\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 14 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 185.773\n",
      "Time elapsed since the last checkpoint : 10.291\n",
      "Time elapsed for the last epoc training: 10.246\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.16\n",
      "Cumulative testb loss over the last epoc: 0.239\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.924\n",
      "Cumulative testb precision over the last epoc: 0.886\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.981\n",
      "Cumulative testa recall over the last epoc: 0.876\n",
      "Cumulative testb recall over the last epoc: 0.837\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.986\n",
      "Cumulative testa f1_score over the last epoc: 0.899\n",
      "Cumulative testb f1_score over the last epoc: 0.861\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 15 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 197.956\n",
      "Time elapsed since the last checkpoint : 12.181\n",
      "Time elapsed for the last epoc training: 12.137\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.171\n",
      "Cumulative testb loss over the last epoc: 0.265\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.925\n",
      "Cumulative testb precision over the last epoc: 0.887\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.979\n",
      "Cumulative testa recall over the last epoc: 0.864\n",
      "Cumulative testb recall over the last epoc: 0.823\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.985\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.854\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 16 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 208.522\n",
      "Time elapsed since the last checkpoint : 10.565\n",
      "Time elapsed for the last epoc training: 10.52\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.182\n",
      "Cumulative testb loss over the last epoc: 0.268\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.921\n",
      "Cumulative testb precision over the last epoc: 0.886\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.978\n",
      "Cumulative testa recall over the last epoc: 0.875\n",
      "Cumulative testb recall over the last epoc: 0.823\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.984\n",
      "Cumulative testa f1_score over the last epoc: 0.897\n",
      "Cumulative testb f1_score over the last epoc: 0.853\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 17 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 219.279\n",
      "Time elapsed since the last checkpoint : 10.755\n",
      "Time elapsed for the last epoc training: 10.712\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.196\n",
      "Cumulative testb loss over the last epoc: 0.291\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.916\n",
      "Cumulative testb precision over the last epoc: 0.875\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.976\n",
      "Cumulative testa recall over the last epoc: 0.861\n",
      "Cumulative testb recall over the last epoc: 0.819\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.983\n",
      "Cumulative testa f1_score over the last epoc: 0.888\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 18 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 229.906\n",
      "Time elapsed since the last checkpoint : 10.626\n",
      "Time elapsed for the last epoc training: 10.582\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.014\n",
      "Cumulative testa loss over the last epoc: 0.205\n",
      "Cumulative testb loss over the last epoc: 0.322\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.964\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.926\n",
      "Cumulative testb precision over the last epoc: 0.875\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.977\n",
      "Cumulative testa recall over the last epoc: 0.871\n",
      "Cumulative testb recall over the last epoc: 0.825\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.983\n",
      "Cumulative testa f1_score over the last epoc: 0.898\n",
      "Cumulative testb f1_score over the last epoc: 0.849\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 19 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 240.162\n",
      "Time elapsed since the last checkpoint : 10.255\n",
      "Time elapsed for the last epoc training: 10.209\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.015\n",
      "Cumulative testa loss over the last epoc: 0.222\n",
      "Cumulative testb loss over the last epoc: 0.33\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.92\n",
      "Cumulative testb precision over the last epoc: 0.878\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.973\n",
      "Cumulative testa recall over the last epoc: 0.864\n",
      "Cumulative testb recall over the last epoc: 0.818\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.981\n",
      "Cumulative testa f1_score over the last epoc: 0.891\n",
      "Cumulative testb f1_score over the last epoc: 0.847\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 20 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 250.342\n",
      "Time elapsed since the last checkpoint : 10.179\n",
      "Time elapsed for the last epoc training: 10.134\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.015\n",
      "Cumulative testa loss over the last epoc: 0.235\n",
      "Cumulative testb loss over the last epoc: 0.329\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.916\n",
      "Cumulative testb precision over the last epoc: 0.879\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.973\n",
      "Cumulative testa recall over the last epoc: 0.861\n",
      "Cumulative testb recall over the last epoc: 0.826\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.981\n",
      "Cumulative testa f1_score over the last epoc: 0.888\n",
      "Cumulative testb f1_score over the last epoc: 0.852\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 21 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 260.81\n",
      "Time elapsed since the last checkpoint : 10.467\n",
      "Time elapsed for the last epoc training: 10.417\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.013\n",
      "Cumulative testa loss over the last epoc: 0.236\n",
      "Cumulative testb loss over the last epoc: 0.343\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.996\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.918\n",
      "Cumulative testb precision over the last epoc: 0.87\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.977\n",
      "Cumulative testa recall over the last epoc: 0.872\n",
      "Cumulative testb recall over the last epoc: 0.823\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.983\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 22 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 273.868\n",
      "Time elapsed since the last checkpoint : 13.056\n",
      "Time elapsed for the last epoc training: 13.008\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.01\n",
      "Cumulative testa loss over the last epoc: 0.233\n",
      "Cumulative testb loss over the last epoc: 0.376\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.963\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.989\n",
      "Cumulative testa precision over the last epoc: 0.914\n",
      "Cumulative testb precision over the last epoc: 0.866\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.984\n",
      "Cumulative testa recall over the last epoc: 0.873\n",
      "Cumulative testb recall over the last epoc: 0.827\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 23 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 285.56\n",
      "Time elapsed since the last checkpoint : 11.69\n",
      "Time elapsed for the last epoc training: 11.649\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.01\n",
      "Cumulative testa loss over the last epoc: 0.242\n",
      "Cumulative testb loss over the last epoc: 0.368\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.917\n",
      "Cumulative testb precision over the last epoc: 0.868\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.98\n",
      "Cumulative testa recall over the last epoc: 0.866\n",
      "Cumulative testb recall over the last epoc: 0.821\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.985\n",
      "Cumulative testa f1_score over the last epoc: 0.891\n",
      "Cumulative testb f1_score over the last epoc: 0.844\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 24 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 296.152\n",
      "Time elapsed since the last checkpoint : 10.59\n",
      "Time elapsed for the last epoc training: 10.546\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.008\n",
      "Cumulative testa loss over the last epoc: 0.242\n",
      "Cumulative testb loss over the last epoc: 0.374\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.991\n",
      "Cumulative testa precision over the last epoc: 0.911\n",
      "Cumulative testb precision over the last epoc: 0.869\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.986\n",
      "Cumulative testa recall over the last epoc: 0.877\n",
      "Cumulative testb recall over the last epoc: 0.831\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.989\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.85\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 25 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 307.478\n",
      "Time elapsed since the last checkpoint : 11.325\n",
      "Time elapsed for the last epoc training: 11.272\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.248\n",
      "Cumulative testb loss over the last epoc: 0.371\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.913\n",
      "Cumulative testb precision over the last epoc: 0.879\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.984\n",
      "Cumulative testa recall over the last epoc: 0.87\n",
      "Cumulative testb recall over the last epoc: 0.832\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.988\n",
      "Cumulative testa f1_score over the last epoc: 0.891\n",
      "Cumulative testb f1_score over the last epoc: 0.855\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 26 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 317.574\n",
      "Time elapsed since the last checkpoint : 10.095\n",
      "Time elapsed for the last epoc training: 10.054\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.012\n",
      "Cumulative testa loss over the last epoc: 0.27\n",
      "Cumulative testb loss over the last epoc: 0.403\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.99\n",
      "Cumulative testa precision over the last epoc: 0.914\n",
      "Cumulative testb precision over the last epoc: 0.873\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.98\n",
      "Cumulative testa recall over the last epoc: 0.864\n",
      "Cumulative testb recall over the last epoc: 0.828\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.985\n",
      "Cumulative testa f1_score over the last epoc: 0.889\n",
      "Cumulative testb f1_score over the last epoc: 0.85\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 27 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 328.479\n",
      "Time elapsed since the last checkpoint : 10.903\n",
      "Time elapsed for the last epoc training: 10.855\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.007\n",
      "Cumulative testa loss over the last epoc: 0.27\n",
      "Cumulative testb loss over the last epoc: 0.408\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.868\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.989\n",
      "Cumulative testa recall over the last epoc: 0.872\n",
      "Cumulative testb recall over the last epoc: 0.829\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.991\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 28 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 344.037\n",
      "Time elapsed since the last checkpoint : 15.557\n",
      "Time elapsed for the last epoc training: 15.512\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.278\n",
      "Cumulative testb loss over the last epoc: 0.419\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.99\n",
      "Cumulative testa precision over the last epoc: 0.915\n",
      "Cumulative testb precision over the last epoc: 0.869\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.986\n",
      "Cumulative testa recall over the last epoc: 0.876\n",
      "Cumulative testb recall over the last epoc: 0.834\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.988\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.851\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 29 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 355.261\n",
      "Time elapsed since the last checkpoint : 11.223\n",
      "Time elapsed for the last epoc training: 11.129\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.008\n",
      "Cumulative testa loss over the last epoc: 0.281\n",
      "Cumulative testb loss over the last epoc: 0.42\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.886\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.985\n",
      "Cumulative testa recall over the last epoc: 0.87\n",
      "Cumulative testb recall over the last epoc: 0.832\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.989\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.858\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 30 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 365.588\n",
      "Time elapsed since the last checkpoint : 10.327\n",
      "Time elapsed for the last epoc training: 10.283\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.3\n",
      "Cumulative testb loss over the last epoc: 0.451\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.964\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.927\n",
      "Cumulative testb precision over the last epoc: 0.877\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.981\n",
      "Cumulative testa recall over the last epoc: 0.866\n",
      "Cumulative testb recall over the last epoc: 0.818\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 31 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 375.775\n",
      "Time elapsed since the last checkpoint : 10.186\n",
      "Time elapsed for the last epoc training: 10.141\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.307\n",
      "Cumulative testb loss over the last epoc: 0.455\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.869\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.984\n",
      "Cumulative testa recall over the last epoc: 0.868\n",
      "Cumulative testb recall over the last epoc: 0.829\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.988\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.849\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 32 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 385.818\n",
      "Time elapsed since the last checkpoint : 10.043\n",
      "Time elapsed for the last epoc training: 9.99\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.312\n",
      "Cumulative testb loss over the last epoc: 0.464\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.875\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.982\n",
      "Cumulative testa recall over the last epoc: 0.869\n",
      "Cumulative testb recall over the last epoc: 0.828\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.851\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 33 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 396.404\n",
      "Time elapsed since the last checkpoint : 10.585\n",
      "Time elapsed for the last epoc training: 10.537\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.325\n",
      "Cumulative testb loss over the last epoc: 0.459\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.993\n",
      "Cumulative testa precision over the last epoc: 0.923\n",
      "Cumulative testb precision over the last epoc: 0.873\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.982\n",
      "Cumulative testa recall over the last epoc: 0.866\n",
      "Cumulative testb recall over the last epoc: 0.823\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.847\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 34 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 406.707\n",
      "Time elapsed since the last checkpoint : 10.302\n",
      "Time elapsed for the last epoc training: 10.255\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.014\n",
      "Cumulative testa loss over the last epoc: 0.349\n",
      "Cumulative testb loss over the last epoc: 0.499\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.874\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.982\n",
      "Cumulative testa recall over the last epoc: 0.872\n",
      "Cumulative testb recall over the last epoc: 0.83\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.851\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 35 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 418.903\n",
      "Time elapsed since the last checkpoint : 12.194\n",
      "Time elapsed for the last epoc training: 12.144\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.01\n",
      "Cumulative testa loss over the last epoc: 0.349\n",
      "Cumulative testb loss over the last epoc: 0.49\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.997\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.993\n",
      "Cumulative testa precision over the last epoc: 0.922\n",
      "Cumulative testb precision over the last epoc: 0.879\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.981\n",
      "Cumulative testa recall over the last epoc: 0.866\n",
      "Cumulative testb recall over the last epoc: 0.823\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.987\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.85\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 36 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 429.917\n",
      "Time elapsed since the last checkpoint : 11.013\n",
      "Time elapsed for the last epoc training: 10.962\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.01\n",
      "Cumulative testa loss over the last epoc: 0.356\n",
      "Cumulative testb loss over the last epoc: 0.536\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.964\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.916\n",
      "Cumulative testb precision over the last epoc: 0.867\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.983\n",
      "Cumulative testa recall over the last epoc: 0.867\n",
      "Cumulative testb recall over the last epoc: 0.825\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.988\n",
      "Cumulative testa f1_score over the last epoc: 0.89\n",
      "Cumulative testb f1_score over the last epoc: 0.845\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 37 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 440.302\n",
      "Time elapsed since the last checkpoint : 10.383\n",
      "Time elapsed for the last epoc training: 10.328\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.352\n",
      "Cumulative testb loss over the last epoc: 0.524\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.868\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.984\n",
      "Cumulative testa recall over the last epoc: 0.869\n",
      "Cumulative testb recall over the last epoc: 0.827\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.988\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.847\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 38 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 450.665\n",
      "Time elapsed since the last checkpoint : 10.361\n",
      "Time elapsed for the last epoc training: 10.313\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.384\n",
      "Cumulative testb loss over the last epoc: 0.539\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.923\n",
      "Cumulative testb precision over the last epoc: 0.874\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.985\n",
      "Cumulative testa recall over the last epoc: 0.867\n",
      "Cumulative testb recall over the last epoc: 0.822\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.99\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 39 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 461.148\n",
      "Time elapsed since the last checkpoint : 10.482\n",
      "Time elapsed for the last epoc training: 10.432\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.381\n",
      "Cumulative testb loss over the last epoc: 0.535\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.993\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.876\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.984\n",
      "Cumulative testa recall over the last epoc: 0.872\n",
      "Cumulative testb recall over the last epoc: 0.826\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.989\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.85\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 40 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 471.787\n",
      "Time elapsed since the last checkpoint : 10.637\n",
      "Time elapsed for the last epoc training: 10.59\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.01\n",
      "Cumulative testa loss over the last epoc: 0.376\n",
      "Cumulative testb loss over the last epoc: 0.565\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.964\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.92\n",
      "Cumulative testb precision over the last epoc: 0.863\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.987\n",
      "Cumulative testa recall over the last epoc: 0.87\n",
      "Cumulative testb recall over the last epoc: 0.823\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.99\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.842\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 41 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 482.483\n",
      "Time elapsed since the last checkpoint : 10.696\n",
      "Time elapsed for the last epoc training: 10.65\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.008\n",
      "Cumulative testa loss over the last epoc: 0.4\n",
      "Cumulative testb loss over the last epoc: 0.574\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.992\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.865\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.988\n",
      "Cumulative testa recall over the last epoc: 0.877\n",
      "Cumulative testb recall over the last epoc: 0.829\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.99\n",
      "Cumulative testa f1_score over the last epoc: 0.897\n",
      "Cumulative testb f1_score over the last epoc: 0.847\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 42 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 495.592\n",
      "Time elapsed since the last checkpoint : 13.107\n",
      "Time elapsed for the last epoc training: 13.052\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.008\n",
      "Cumulative testa loss over the last epoc: 0.387\n",
      "Cumulative testb loss over the last epoc: 0.588\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.964\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.993\n",
      "Cumulative testa precision over the last epoc: 0.917\n",
      "Cumulative testb precision over the last epoc: 0.863\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.99\n",
      "Cumulative testa recall over the last epoc: 0.876\n",
      "Cumulative testb recall over the last epoc: 0.829\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.991\n",
      "Cumulative testa f1_score over the last epoc: 0.896\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 43 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 506.832\n",
      "Time elapsed since the last checkpoint : 11.238\n",
      "Time elapsed for the last epoc training: 11.185\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.41\n",
      "Cumulative testb loss over the last epoc: 0.608\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.918\n",
      "Cumulative testb precision over the last epoc: 0.868\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.988\n",
      "Cumulative testa recall over the last epoc: 0.871\n",
      "Cumulative testb recall over the last epoc: 0.825\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.991\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 44 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 517.364\n",
      "Time elapsed since the last checkpoint : 10.532\n",
      "Time elapsed for the last epoc training: 10.478\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.011\n",
      "Cumulative testa loss over the last epoc: 0.421\n",
      "Cumulative testb loss over the last epoc: 0.599\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.92\n",
      "Cumulative testb precision over the last epoc: 0.875\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.986\n",
      "Cumulative testa recall over the last epoc: 0.87\n",
      "Cumulative testb recall over the last epoc: 0.829\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.99\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.852\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 45 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 529.189\n",
      "Time elapsed since the last checkpoint : 11.824\n",
      "Time elapsed for the last epoc training: 11.777\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.431\n",
      "Cumulative testb loss over the last epoc: 0.622\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.917\n",
      "Cumulative testb precision over the last epoc: 0.877\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.986\n",
      "Cumulative testa recall over the last epoc: 0.865\n",
      "Cumulative testb recall over the last epoc: 0.822\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.99\n",
      "Cumulative testa f1_score over the last epoc: 0.89\n",
      "Cumulative testb f1_score over the last epoc: 0.849\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 46 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 539.911\n",
      "Time elapsed since the last checkpoint : 10.72\n",
      "Time elapsed for the last epoc training: 10.671\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.009\n",
      "Cumulative testa loss over the last epoc: 0.453\n",
      "Cumulative testb loss over the last epoc: 0.612\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.967\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.995\n",
      "Cumulative testa precision over the last epoc: 0.928\n",
      "Cumulative testb precision over the last epoc: 0.88\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.987\n",
      "Cumulative testa recall over the last epoc: 0.874\n",
      "Cumulative testb recall over the last epoc: 0.825\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.991\n",
      "Cumulative testa f1_score over the last epoc: 0.9\n",
      "Cumulative testb f1_score over the last epoc: 0.852\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 47 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 551.497\n",
      "Time elapsed since the last checkpoint : 11.584\n",
      "Time elapsed for the last epoc training: 11.539\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.008\n",
      "Cumulative testa loss over the last epoc: 0.439\n",
      "Cumulative testb loss over the last epoc: 0.63\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.993\n",
      "Cumulative testa precision over the last epoc: 0.915\n",
      "Cumulative testb precision over the last epoc: 0.866\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.99\n",
      "Cumulative testa recall over the last epoc: 0.875\n",
      "Cumulative testb recall over the last epoc: 0.826\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.992\n",
      "Cumulative testa f1_score over the last epoc: 0.895\n",
      "Cumulative testb f1_score over the last epoc: 0.846\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 48 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 562.621\n",
      "Time elapsed since the last checkpoint : 11.124\n",
      "Time elapsed for the last epoc training: 11.073\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.008\n",
      "Cumulative testa loss over the last epoc: 0.471\n",
      "Cumulative testb loss over the last epoc: 0.656\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.978\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.994\n",
      "Cumulative testa precision over the last epoc: 0.919\n",
      "Cumulative testb precision over the last epoc: 0.868\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.989\n",
      "Cumulative testa recall over the last epoc: 0.877\n",
      "Cumulative testb recall over the last epoc: 0.83\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.991\n",
      "Cumulative testa f1_score over the last epoc: 0.897\n",
      "Cumulative testb f1_score over the last epoc: 0.849\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 49 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 574.052\n",
      "Time elapsed since the last checkpoint : 11.429\n",
      "Time elapsed for the last epoc training: 11.374\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.007\n",
      "Cumulative testa loss over the last epoc: 0.481\n",
      "Cumulative testb loss over the last epoc: 0.655\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.998\n",
      "Cumulative testa accuracy over the last epoc: 0.976\n",
      "Cumulative testb accuracy over the last epoc: 0.966\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.996\n",
      "Cumulative testa precision over the last epoc: 0.918\n",
      "Cumulative testb precision over the last epoc: 0.879\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.989\n",
      "Cumulative testa recall over the last epoc: 0.87\n",
      "Cumulative testb recall over the last epoc: 0.822\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.992\n",
      "Cumulative testa f1_score over the last epoc: 0.893\n",
      "Cumulative testb f1_score over the last epoc: 0.85\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 50 of 50 completed.\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Time elapsed during training so far    : 584.135\n",
      "Time elapsed since the last checkpoint : 10.082\n",
      "Time elapsed for the last epoc training: 10.036\n",
      "\n",
      "\n",
      "Cumulative train loss over the last epoc: 0.008\n",
      "Cumulative testa loss over the last epoc: 0.466\n",
      "Cumulative testb loss over the last epoc: 0.639\n",
      "\n",
      "\n",
      "Cumulative train accuracy over the last epoc: 0.999\n",
      "Cumulative testa accuracy over the last epoc: 0.977\n",
      "Cumulative testb accuracy over the last epoc: 0.965\n",
      "\n",
      "\n",
      "Cumulative train precision over the last epoc: 0.995\n",
      "Cumulative testa precision over the last epoc: 0.918\n",
      "Cumulative testb precision over the last epoc: 0.879\n",
      "\n",
      "\n",
      "Cumulative train recall over the last epoc: 0.989\n",
      "Cumulative testa recall over the last epoc: 0.871\n",
      "Cumulative testb recall over the last epoc: 0.824\n",
      "\n",
      "\n",
      "Cumulative train f1_score over the last epoc: 0.992\n",
      "Cumulative testa f1_score over the last epoc: 0.894\n",
      "Cumulative testb f1_score over the last epoc: 0.851\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# word-level\n",
    "\n",
    "nn_design_list = [{'layer_type': 'full_cn', 'output_shape': [300], 'activation': 'relu'},\n",
    "                  {'layer_type': 'full_cn', 'output_shape': [len(const.LIST_KEYWORD_TAGS)]}]\n",
    "\n",
    "model_details_dict = {'project_name': 'reuters',\n",
    "                      'loss_type': 'word_level',\n",
    "                      'nn_design_list': nn_design_list,\n",
    "                      'wdvec_name': 'wdvec_2018-07-26T13-02-36.910667',\n",
    "                      'model_name': 'reuters_model'} # 'reuters_model_2019-03-21T15-44-56.214733'}\n",
    "\n",
    "with SennaNER(model_details_dict) as senna_ner:\n",
    "    \n",
    "    senna_ner.train_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tfenv",
   "language": "python",
   "name": ".tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
